# -*- coding: utf-8 -*-

"""LlamaIndexã‚µãƒ³ãƒ—ãƒ«

LlamaIndexã‚’ä½¿ç”¨ã—ã¦ã€å¤–éƒ¨ã®ãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ã‚’å‚ç…§ã—ã¦
å›ç­”ã‚’ã•ã›ã‚‹ã‚µãƒ³ãƒ—ãƒ«

"""

import streamlit as st
from langchain.chat_models import ChatOpenAI
from llama_index import (
    QuestionAnswerPrompt,
    GPTVectorStoreIndex,
    SimpleDirectoryReader,
    ServiceContext,
    LLMPredictor,
    StorageContext,
    load_index_from_storage,
)
import openai
import logging
import sys
import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# Open AI APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = os.environ["OPENAI_API_KEY"]

# ãƒ­ã‚°ã®è¨­å®š
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)

# ã‚µãƒ¼ãƒ“ã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
service_context = ServiceContext.from_defaults(
    llm_predictor=LLMPredictor(llm=ChatOpenAI(model_name="gpt-3.5-turbo"))
)

# # å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
# dir_path = os.path.dirname(os.path.realpath(__file__))

# # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆï¼Šåˆå›ã®ã¿å®Ÿè¡Œï¼‰
# documents = SimpleDirectoryReader(os.path.join(dir_path, "data")).load_data()
# # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆï¼ˆï¼Šåˆå›ã®ã¿å®Ÿè¡Œï¼‰
# index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)
# # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜ï¼ˆï¼Šåˆå›ã®ã¿å®Ÿè¡Œï¼‰
# index.storage_context.persist()

# ä¿å­˜æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
query_engine = index.as_query_engine()

# ã‚¿ã‚¤ãƒˆãƒ«ã®ä½œæˆ
st.title("ğŸŸLlamaIndexã®ã‚µãƒ³ãƒ—ãƒ«ğŸŸ")
st.text("å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™ã€‚")

# ã‚¤ãƒ³ãƒ—ãƒƒãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ä½œæˆ
prompt = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# å…¥åŠ›ãŒã‚ã£ãŸã‚‰OpenAIã®APIã‚’å®Ÿè¡Œ
if prompt:
    try:
        response = query_engine.query(
            f"ã‚ãªãŸã¯åºƒå ±ã§ã™ã€‚ç°¡æ½”ãªæ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚ã¾ãŸæ–‡ç« ã«è¨˜è¼‰ã®ãªã„å ´åˆã¯ãã®æ—¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ ```{prompt}```"
        )
    except Exception as e:
        print("error")
        response = str(e)
    # OpenAIã®å›ç­”ã‚’è¡¨ç¤º
    st.write(response.response)
